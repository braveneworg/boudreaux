name: CI/CD - Build, Publish, Deploy

# This workflow handles deployment to production
# Quality checks (tests, lint, typecheck) are performed by ci.yml
# This workflow only runs after ci.yml passes on the main branch

on:
  workflow_run:
    workflows: ["CI"]
    types:
      - completed
    branches: [main]
  workflow_dispatch:

concurrency:
  group: cicd-${{ github.ref_name }}
  cancel-in-progress: true

env:
  REGISTRY: ghcr.io
  IMAGE_REPO: ghcr.io/${{ github.repository_owner }}/boudreaux
  WEBSITE_IMAGE: ghcr.io/${{ github.repository_owner }}/boudreaux/website
  NGINX_IMAGE: ghcr.io/${{ github.repository_owner }}/boudreaux/nginx

permissions:
  contents: read
  actions: read
  packages: write

jobs:
  download-build:
    name: Download build from CI
    runs-on: ubuntu-latest
    # Only run if CI workflow succeeded
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}
    steps:
      - name: Check artifact presence in triggering CI run
        uses: actions/github-script@v7
        with:
          script: |
            const runId = context.payload.workflow_run?.id;
            if (!runId) {
              core.setFailed('No workflow_run.id found on event payload.');
              return;
            }
            const { data: artifacts } = await github.rest.actions.listWorkflowRunArtifacts({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: runId,
              per_page: 100,
            });
            const names = artifacts.artifacts.map(a => a.name);
            core.info(`Found artifacts on CI run ${runId}: ${names.join(', ') || '(none)'}`);
            if (!names.includes('nextjs-build')) {
              core.setFailed("Missing required artifact 'nextjs-build' from CI run. Ensure ci.yml 'build' job uploaded it.");
            }

      - name: Download build artifact from triggering CI run
        uses: dawidd6/action-download-artifact@v6
        with:
          run_id: ${{ github.event.workflow_run.id }}
          name: nextjs-build
          path: .
          github_token: ${{ secrets.GITHUB_TOKEN }}

      - name: Verify artifact
        run: |
          if [ ! -f "next-build.tar.gz" ]; then
            echo "Error: next-build.tar.gz not found!"
            ls -la
            exit 1
          fi
          ls -lh next-build.tar.gz

      - name: Re-upload for downstream jobs
        uses: actions/upload-artifact@v4
        with:
          name: nextjs-build-deploy
          path: next-build.tar.gz
          retention-days: 1
          if-no-files-found: error

  sync-cdn:
    name: Sync static assets to CDN
    runs-on: ubuntu-latest
    needs: download-build
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "22"
          cache: "npm"

      - name: Install dependencies
        run: npm ci

      - name: Download build artifact
        uses: actions/download-artifact@v4
        with:
          name: nextjs-build-deploy
          path: .

      - name: Extract build
        run: tar -xzf next-build.tar.gz

      - name: Sync to CDN
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          S3_BUCKET: ${{ secrets.S3_BUCKET }}
          CLOUDFRONT_DISTRIBUTION_ID: ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }}
          CDN_DOMAIN: ${{ secrets.CDN_DOMAIN }}
        run: npm run sync:cdn:no-build

  build-images:
    name: Build & push Docker images
    runs-on: ubuntu-latest
    needs: download-build
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download build artifact
        uses: actions/download-artifact@v4
        with:
          name: nextjs-build-deploy
          path: .

      - name: Verify and extract artifact
        run: |
          if [ ! -f "next-build.tar.gz" ]; then
            echo "Error: next-build.tar.gz not found after download!"
            ls -la
            exit 1
          fi
          echo "Artifact downloaded successfully:"
          ls -lh next-build.tar.gz
          # Do not extract here; Dockerfile will consume next-build.tar.gz to avoid rebuilds

      - name: Log in to container registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ secrets.GHCR_USERNAME || github.actor }}
          password: ${{ secrets.GHCR_TOKEN }}

      - name: Setup Docker layer caching
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          install: true
          driver-opts: |
            network=host
            image=moby/buildkit:latest
          buildkitd-flags: --allow-insecure-entitlement network.host --allow-insecure-entitlement security.insecure

      - name: Set up QEMU for cross-arch builds
        uses: docker/setup-qemu-action@v3
        with:
          platforms: all

      - name: Show buildx platforms
        run: docker buildx ls

      - name: Build multi-arch website image (with retry)
        env:
          NEXT_PUBLIC_CLOUDFLARE_SITE_KEY: ${{ secrets.NEXT_PUBLIC_CLOUDFLARE_SITE_KEY }}
        run: |
          set -e
          TOK='${{ secrets.GHCR_TOKEN }}'
          USR='${{ secrets.GHCR_USERNAME }}'

          if [ -z "$TOK" ] || [ -z "$USR" ]; then
            echo "Error: GHCR_TOKEN and GHCR_USERNAME secrets must be set"
            exit 1
          fi

          success=0
          for i in 1 2 3; do
            echo "Attempt $i: Logging in to GHCR..."
            echo "$TOK" | docker login ${{ env.REGISTRY }} -u "$USR" --password-stdin

            if docker buildx build \
              --platform linux/arm64,linux/amd64 \
              --build-arg NEXT_PUBLIC_CLOUDFLARE_SITE_KEY=${NEXT_PUBLIC_CLOUDFLARE_SITE_KEY} \
              --provenance=false \
              --sbom=false \
              --cache-from type=local,src=/tmp/.buildx-cache \
              --cache-from type=registry,ref=${{ env.WEBSITE_IMAGE }}:buildcache \
              --cache-to type=local,dest=/tmp/.buildx-cache-new,mode=max \
              --cache-to type=registry,ref=${{ env.WEBSITE_IMAGE }}:buildcache,mode=max \
              -t ${{ env.WEBSITE_IMAGE }}:latest \
              -f Dockerfile \
              --push .; then
              echo "Website image buildx push succeeded"
              success=1
              # Move cache to avoid growing cache indefinitely
              rm -rf /tmp/.buildx-cache
              mv /tmp/.buildx-cache-new /tmp/.buildx-cache
              break
            fi

            echo "Attempt $i failed; retrying in $((i*10))s..."
            sleep $((i*10))
          done

          if [ "$success" != 1 ]; then
            echo "Website image buildx push failed after 3 attempts"
            exit 1
          fi

  build-nginx:
    name: Build nginx image (with retry)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Log in to container registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ secrets.GHCR_USERNAME || github.actor }}
          password: ${{ secrets.GHCR_TOKEN }}

      - name: Setup Docker layer caching
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          install: true
          driver-opts: |
            network=host
            image=moby/buildkit:latest
          buildkitd-flags: --allow-insecure-entitlement network.host --allow-insecure-entitlement security.insecure

      - name: Set up QEMU for cross-arch builds
        uses: docker/setup-qemu-action@v3
        with:
          platforms: all

      - name: Show buildx platforms
        run: docker buildx ls

      - name: Build multi-arch nginx image (with retry)
        run: |
          set -e
          TOK='${{ secrets.GHCR_TOKEN }}'
          USR='${{ secrets.GHCR_USERNAME }}'

          if [ -z "$TOK" ] || [ -z "$USR" ]; then
            echo "Error: GHCR_TOKEN and GHCR_USERNAME secrets must be set"
            exit 1
          fi

          success=0
          for i in 1 2 3; do
            echo "Attempt $i: Logging in to GHCR..."
            echo "$TOK" | docker login ${{ env.REGISTRY }} -u "$USR" --password-stdin

            if docker buildx build \
              --platform linux/arm64,linux/amd64 \
              --provenance=false \
              --sbom=false \
              --cache-from type=local,src=/tmp/.buildx-cache \
              --cache-from type=registry,ref=${{ env.NGINX_IMAGE }}:buildcache \
              --cache-to type=local,dest=/tmp/.buildx-cache-new,mode=max \
              --cache-to type=registry,ref=${{ env.NGINX_IMAGE }}:buildcache,mode=max \
              -t ${{ env.NGINX_IMAGE }}:latest \
              -f nginx/Dockerfile \
              --push .; then
              echo "Nginx image buildx push succeeded"
              success=1
              # Move cache to avoid growing cache indefinitely
              rm -rf /tmp/.buildx-cache
              mv /tmp/.buildx-cache-new /tmp/.buildx-cache
              break
            fi

            echo "Attempt $i failed; retrying in $((i*10))s..."
            sleep $((i*10))
          done

          if [ "$success" != 1 ]; then
            echo "Nginx image buildx push failed after 3 attempts"
            exit 1
          fi

      - name: Capture multi-arch image digests
        run: |
          set -e
          WEBSITE_DIGEST=$(docker buildx imagetools inspect ${{ env.WEBSITE_IMAGE }}:latest | awk '/Digest:/ {print $2; exit}')
          NGINX_DIGEST=$(docker buildx imagetools inspect ${{ env.NGINX_IMAGE }}:latest | awk '/Digest:/ {print $2; exit}')
          echo "Resolved website manifest digest: $WEBSITE_DIGEST"
          echo "Resolved nginx manifest digest: $NGINX_DIGEST"
          echo "WEBSITE_DIGEST=$WEBSITE_DIGEST" >> $GITHUB_ENV
          echo "NGINX_DIGEST=$NGINX_DIGEST" >> $GITHUB_ENV
          printf '{"website":"%s","nginx":"%s"}' "$WEBSITE_DIGEST" "$NGINX_DIGEST" > image-digests.json

      - name: Upload image digest artifact
        uses: actions/upload-artifact@v4
        with:
          name: image-digests
          path: image-digests.json

  deploy:
    name: Deploy to EC2 via SSH with temporary IP allow
    runs-on: ubuntu-latest
    needs: [build-images, sync-cdn]
    permissions:
      contents: read
      id-token: write
    env:
      WEBSITE_IMAGE: ghcr.io/${{ github.repository_owner }}/boudreaux/website
      NGINX_IMAGE: ghcr.io/${{ github.repository_owner }}/boudreaux/nginx
      # Align secret names: ensure AWS_SECURITY_GROUP_ID exists in repo secrets
      AWS_SECURITY_GROUP_ID: ${{ secrets.AWS_SECURITY_GROUP_ID }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download image digests artifact
        uses: actions/download-artifact@v4
        with:
          name: image-digests
          path: .

      - name: Export digest environment variables
        shell: bash
        run: |
          WEBSITE_DIGEST=$(jq -r '.website' image-digests.json)
          NGINX_DIGEST=$(jq -r '.nginx' image-digests.json)
          echo "WEBSITE_DIGEST=$WEBSITE_DIGEST" >> $GITHUB_ENV
          echo "NGINX_DIGEST=$NGINX_DIGEST" >> $GITHUB_ENV

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Get runner public IP
        id: ip
        uses: haythem/public-ip@v1.3

      - name: Temporarily whitelist runner IP for SSH
        run: |
          aws ec2 authorize-security-group-ingress \
            --group-id "$AWS_SECURITY_GROUP_ID" \
            --protocol tcp \
            --port 22 \
            --cidr "${{ steps.ip.outputs.ipv4 }}/32" || true

      - name: Create .env for remote
        run: |
          cat > .env.deploy << 'EOF'
          NEXT_APP_WEBSITE_IMAGE=${{ env.WEBSITE_IMAGE }}
          NEXT_APP_NGINX_IMAGE=${{ env.NGINX_IMAGE }}
          DATABASE_URL=${{ secrets.DATABASE_URL }}
          AUTH_SECRET=${{ secrets.AUTH_SECRET }}
          # Align secret names: ensure NEXTAUTH_URL exists; if older name used, set alias in repo settings
          NEXTAUTH_URL=${{ secrets.NEXTAUTH_URL }}
          EMAIL_SERVER_HOST=${{ secrets.EMAIL_SERVER_HOST }}
          EMAIL_SERVER_PORT=${{ secrets.EMAIL_SERVER_PORT }}
          EMAIL_SERVER_USER=${{ secrets.EMAIL_SERVER_USER }}
          EMAIL_SERVER_PASSWORD=${{ secrets.EMAIL_SERVER_PASSWORD }}
          EMAIL_FROM=${{ secrets.EMAIL_FROM }}
          NEXT_PUBLIC_CLOUDFLARE_SITE_KEY=${{ secrets.NEXT_PUBLIC_CLOUDFLARE_SITE_KEY }}
          CLOUDFLARE_SECRET=${{ secrets.CLOUDFLARE_SECRET }}
          EOF

      - name: Upload compose + env
        uses: appleboy/scp-action@v0.1.7
        with:
          # Align secret names: EC2_HOST, EC2_USERNAME, SSH_PRIVATE_KEY
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USERNAME }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          source: docker-compose.prod.yml,.env.deploy
          target: ~/boudreaux

      - name: Deploy via SSH
        uses: appleboy/ssh-action@v1.2.0
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USERNAME }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          timeout: 60s
          command_timeout: 30m
          envs: WEBSITE_DIGEST,NGINX_DIGEST
          script: |
            set -euo pipefail

            # Ensure SSH authorized_keys has correct permissions
            mkdir -p ~/.ssh
            chmod 700 ~/.ssh
            if [ -f ~/.ssh/authorized_keys ]; then
              chmod 600 ~/.ssh/authorized_keys
            fi

            cd ~/boudreaux

            # Ensure Docker is installed and running (Ubuntu)
            if ! command -v docker >/dev/null 2>&1; then
              sudo apt-get update
              sudo apt-get remove -y docker.io docker-doc docker-compose podman-docker containerd runc 2>/dev/null || true
              sudo apt-get install -y ca-certificates curl gnupg lsb-release
              if [ ! -f /etc/apt/keyrings/docker.gpg ]; then
                sudo install -m 0755 -d /etc/apt/keyrings
                curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
                sudo chmod a+r /etc/apt/keyrings/docker.gpg
                echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
                sudo apt-get update
              fi
              sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
              sudo systemctl enable docker
              sudo systemctl start docker
            fi

            # Ensure user is in docker group (required for non-root Docker access)
            if ! groups | grep -q docker; then
              echo "Adding $USER to docker group..."
              sudo usermod -aG docker $USER
              echo "User added to docker group. Note: This session will use 'sudo docker' for remaining commands."
              echo "Subsequent deployments will not need sudo after the user logs out and back in."
            fi

            # Check if we can access Docker without sudo (define DOCKER_CMD early)
            if docker ps >/dev/null 2>&1; then
              DOCKER_CMD="docker"
            else
              echo "Using sudo for Docker commands (group membership not yet active in this session)"
              DOCKER_CMD="sudo docker"
            fi

            # Install certbot if not present (one-time setup)
            if ! command -v certbot >/dev/null 2>&1; then
              echo "Installing certbot..."
              sudo apt-get update -qq
              sudo apt-get install -y certbot
            fi

            # Setup Let's Encrypt certificates (only if missing)
            DOMAIN="fakefourrecords.com"
            CERT_PATH="/etc/letsencrypt/live/$DOMAIN"

            if [ ! -f "$CERT_PATH/fullchain.pem" ]; then
              echo "Obtaining Let's Encrypt certificate for $DOMAIN..."
              # Stop containers that might be using port 80
              $DOCKER_CMD stop nginx website 2>/dev/null || true

              # Request certificate using standalone mode
              sudo certbot certonly --standalone --non-interactive --agree-tos \
                --email '${{ secrets.LETSENCRYPT_EMAIL }}' \
                -d "$DOMAIN" -d "www.$DOMAIN" || {
                echo "WARNING: Certificate acquisition failed. Attempting deployment without new cert."
              }
            fi

            # Create symlinks if certificates exist
            if [ -f "$CERT_PATH/fullchain.pem" ]; then
              sudo ln -sf "$CERT_PATH/fullchain.pem" ~/boudreaux/certificate.pem
              sudo ln -sf "$CERT_PATH/privkey.pem" ~/boudreaux/private_key.pem
              sudo chmod 644 ~/boudreaux/certificate.pem ~/boudreaux/private_key.pem

              # Setup automatic renewal cron (idempotent)
              if ! sudo crontab -l 2>/dev/null | grep -q "certbot renew"; then
                (sudo crontab -l 2>/dev/null; echo "0 3 * * * certbot renew --quiet --deploy-hook 'docker restart nginx'") | sudo crontab -
              fi
            else
              echo "WARNING: Let's Encrypt certificates not found. HTTPS may not work."
            fi

            # Move env into place and secure permissions
            mv -f .env.deploy .env
            chmod 600 .env  # Owner read/write only

            # Login to GHCR using aligned credentials
            echo '${{ secrets.GHCR_TOKEN }}' | $DOCKER_CMD login ghcr.io -u '${{ secrets.GHCR_USERNAME }}' --password-stdin

            WEBSITE_IMAGE='${{ env.WEBSITE_IMAGE }}'
            NGINX_IMAGE='${{ env.NGINX_IMAGE }}'

            # Capture previously deployed digests (if present)
            PREV_WEBSITE_DIGEST=$($DOCKER_CMD inspect --format '{{index .RepoDigests 0}}' "$WEBSITE_IMAGE" 2>/dev/null || true)
            PREV_NGINX_DIGEST=$($DOCKER_CMD inspect --format '{{index .RepoDigests 0}}' "$NGINX_IMAGE" 2>/dev/null || true)

            # If digests are provided, pin to those; otherwise, use latest and capture digests
            if [ -n "${WEBSITE_DIGEST:-}" ] && [ -n "${NGINX_DIGEST:-}" ]; then
              echo "Using provided digests for deployment"
              # Pull by fully qualified digest (image@sha256:...)
              $DOCKER_CMD pull "$WEBSITE_IMAGE@$WEBSITE_DIGEST" || true
              $DOCKER_CMD pull "$NGINX_IMAGE@$NGINX_DIGEST" || true
              # Tag with :latest for compose to use
              $DOCKER_CMD tag "$WEBSITE_IMAGE@$WEBSITE_DIGEST" "$WEBSITE_IMAGE:latest" || true
              $DOCKER_CMD tag "$NGINX_IMAGE@$NGINX_DIGEST" "$NGINX_IMAGE:latest" || true
              NEW_WEBSITE_DIGEST="$WEBSITE_IMAGE@$WEBSITE_DIGEST"
              NEW_NGINX_DIGEST="$NGINX_IMAGE@$NGINX_DIGEST"
            else
              echo "No digests provided; using latest tags"
              $DOCKER_CMD pull "$WEBSITE_IMAGE:latest" || true
              $DOCKER_CMD pull "$NGINX_IMAGE:latest" || true
              NEW_WEBSITE_DIGEST=$($DOCKER_CMD inspect --format '{{index .RepoDigests 0}}' "$WEBSITE_IMAGE:latest" 2>/dev/null || true)
              NEW_NGINX_DIGEST=$($DOCKER_CMD inspect --format '{{index .RepoDigests 0}}' "$NGINX_IMAGE:latest" 2>/dev/null || true)
            fi

            # Restart stack (force remove any conflicting containers)
            $DOCKER_CMD compose -f docker-compose.prod.yml down --remove-orphans || true

            # Remove any containers with conflicting names
            $DOCKER_CMD rm -f website nginx 2>/dev/null || true

            $DOCKER_CMD compose -f docker-compose.prod.yml up -d

            # Basic health check
            sleep 5
            if ! curl -fsS --max-time 10 https://fakefourrecords.com/api/health; then
              echo 'Health check failed - attempting rollback'

              # Roll back to previous digests if we have them
              if [ -n "$PREV_WEBSITE_DIGEST" ]; then
                # Ensure previous digest is present and retag as :latest
                $DOCKER_CMD pull "$PREV_WEBSITE_DIGEST" || true
                $DOCKER_CMD tag "$PREV_WEBSITE_DIGEST" "$WEBSITE_IMAGE:latest" || true
              fi
              if [ -n "$PREV_NGINX_DIGEST" ]; then
                $DOCKER_CMD pull "$PREV_NGINX_DIGEST" || true
                $DOCKER_CMD tag "$PREV_NGINX_DIGEST" "$NGINX_IMAGE:latest" || true
              fi

              $DOCKER_CMD compose -f docker-compose.prod.yml up -d --force-recreate
              sleep 5
              if ! curl -fsS --max-time 10 https://fakefourrecords.com/api/health; then
                echo 'Rollback health check failed - manual intervention required'
                exit 1
              else
                echo 'Rollback successful'
              fi
            fi

            # Persist current digests on host for audit/rollback reference
            mkdir -p .deploy
            cat > .deploy/digests.json <<JSON
            {
              "website": {
                "prev": "${PREV_WEBSITE_DIGEST}",
                "current": "${NEW_WEBSITE_DIGEST}"
              },
              "nginx": {
                "prev": "${PREV_NGINX_DIGEST}",
                "current": "${NEW_NGINX_DIGEST}"
              }
            }
            JSON

            $DOCKER_CMD system prune -f || true

      - name: Revoke runner IP
        if: always()
        run: |
          aws ec2 revoke-security-group-ingress \
            --group-id "$AWS_SECURITY_GROUP_ID" \
            --protocol tcp \
            --port 22 \
            --cidr "${{ steps.ip.outputs.ipv4 }}/32" || true
