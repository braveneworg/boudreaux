name: CI/CD - Build, Publish, Deploy

# This workflow handles deployment to production
# Quality checks (tests, lint, typecheck) are performed by ci.yml
# This workflow only runs after ci.yml passes on the main branch

on:
  workflow_run:
    workflows: ["CI"]
    types:
      - completed
    branches: [main]

concurrency:
  group: cicd-${{ github.ref_name }}
  cancel-in-progress: true

env:
  REGISTRY: ghcr.io
  IMAGE_REPO: ghcr.io/${{ github.repository_owner }}/boudreaux
  WEBSITE_IMAGE: ghcr.io/${{ github.repository_owner }}/boudreaux/website
  NGINX_IMAGE: ghcr.io/${{ github.repository_owner }}/boudreaux/nginx

permissions:
  contents: read
  actions: read
  packages: write

jobs:
  build-images:
    name: Build & push website image
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    outputs:
      digest: ${{ steps.capture-digest.outputs.digest }}
    steps:
      - name: Check artifact presence in triggering CI run
        uses: actions/github-script@v7
        with:
          script: |
            const runId = context.payload.workflow_run?.id;
            if (!runId) {
              core.setFailed('No workflow_run.id found on event payload.');
              return;
            }
            const runUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${runId}`;
            core.info(`CI run URL: ${runUrl}`);
            const { data: artifacts } = await github.rest.actions.listWorkflowRunArtifacts({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: runId,
              per_page: 100,
            });
            const names = artifacts.artifacts.map(a => a.name);
            core.info(`Found artifacts on CI run ${runId}: ${names.join(', ') || '(none)'}`);
            if (!names.includes('nextjs-build')) {
              core.setFailed("Missing required artifact 'nextjs-build' from CI run. Ensure ci.yml 'build' job uploaded it.");
            }

      - name: Checkout
        uses: actions/checkout@v4

      - name: Download build artifact from CI run
        uses: dawidd6/action-download-artifact@v6
        with:
          run_id: ${{ github.event.workflow_run.id }}
          name: nextjs-build
          path: .
          github_token: ${{ secrets.GITHUB_TOKEN }}

      - name: Verify and extract artifact
        run: |
          if [ ! -f "next-build.tar.gz" ]; then
            echo "Error: next-build.tar.gz not found after download!"
            ls -la
            exit 1
          fi
          echo "Artifact downloaded successfully:"
          ls -lh next-build.tar.gz

          # Extract to verify build
          echo "Extracting to verify build..."
          tar -xzf next-build.tar.gz

          if [ -f ".next/BUILD_ID" ]; then
            BUILD_ID=$(cat .next/BUILD_ID)
            echo "BUILD_ID in Docker image build: $BUILD_ID"
            echo "DOCKER_BUILD_ID=$BUILD_ID" >> $GITHUB_ENV
          fi

          # Clean up extraction (Dockerfile will extract fresh)
          rm -rf .next

          echo "✓ Build artifact verified and ready for Docker build"

      - name: Log in to container registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ secrets.GHCR_USERNAME || github.actor }}
          password: ${{ secrets.GHCR_TOKEN }}

      - name: Setup Docker layer caching
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-website-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-website-

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          install: true
          driver-opts: |
            network=host
            image=moby/buildkit:latest
          buildkitd-flags: --allow-insecure-entitlement network.host --allow-insecure-entitlement security.insecure

      - name: Build website image (single-arch for speed)
        env:
          NEXT_PUBLIC_CLOUDFLARE_SITE_KEY: ${{ secrets.NEXT_PUBLIC_CLOUDFLARE_SITE_KEY }}
        run: |
          set -e
          TOK='${{ secrets.GHCR_TOKEN }}'
          USR='${{ secrets.GHCR_USERNAME }}'

          if [ -z "$TOK" ] || [ -z "$USR" ]; then
            echo "Error: GHCR_TOKEN and GHCR_USERNAME secrets must be set"
            exit 1
          fi

          # Use BUILD_ID from previous step or timestamp as cache buster
          CACHE_BUST="${DOCKER_BUILD_ID:-$(date +%s)}"
          echo "Using CACHE_BUST=${CACHE_BUST} to force fresh artifact extraction"

          success=0
          for i in 1 2 3; do
            echo "Attempt $i: Logging in to GHCR..."
            echo "$TOK" | docker login ${{ env.REGISTRY }} -u "$USR" --password-stdin

            # Build for linux/amd64 only (most EC2 instances) for faster builds (~3-4 min vs 8-12 min)
            # Change to linux/arm64 if using ARM-based EC2 instances (Graviton)
            if docker buildx build \
              --platform linux/amd64 \
              --build-arg NEXT_PUBLIC_CLOUDFLARE_SITE_KEY=${NEXT_PUBLIC_CLOUDFLARE_SITE_KEY} \
              --build-arg CACHE_BUST=${CACHE_BUST} \
              --provenance=false \
              --sbom=false \
              --cache-from type=local,src=/tmp/.buildx-cache \
              --cache-from type=registry,ref=${{ env.WEBSITE_IMAGE }}:buildcache \
              --cache-to type=local,dest=/tmp/.buildx-cache-new,mode=max \
              --cache-to type=registry,ref=${{ env.WEBSITE_IMAGE }}:buildcache,mode=max \
              -t ${{ env.WEBSITE_IMAGE }}:latest \
              -f Dockerfile \
              --push .; then
              echo "Website image buildx push succeeded"
              success=1
              # Move cache to avoid growing cache indefinitely
              rm -rf /tmp/.buildx-cache
              mv /tmp/.buildx-cache-new /tmp/.buildx-cache
              break
            fi

            echo "Attempt $i failed; retrying in $((i*10))s..."
            sleep $((i*10))
          done

          if [ "$success" != 1 ]; then
            echo "Website image buildx push failed after 3 attempts"
            exit 1
          fi

      - name: Capture image digest
        id: capture-digest
        run: |
          set -e
          echo "Fetching website image digest..."
          DIGEST=$(docker buildx imagetools inspect ${{ env.WEBSITE_IMAGE }}:latest --format '{{json .}}' | jq -r '.manifest.digest')
          echo "Website digest: $DIGEST"

          if [ -z "$DIGEST" ] || [ "$DIGEST" = "null" ]; then
            echo "ERROR: Failed to get website digest"
            exit 1
          fi

          echo "digest=$DIGEST" >> $GITHUB_OUTPUT

  build-nginx:
    name: Build & push nginx image
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    outputs:
      digest: ${{ steps.capture-digest.outputs.digest }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Log in to container registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ secrets.GHCR_USERNAME || github.actor }}
          password: ${{ secrets.GHCR_TOKEN }}

      - name: Setup Docker layer caching
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-nginx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-nginx-

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          install: true
          driver-opts: |
            network=host
            image=moby/buildkit:latest
          buildkitd-flags: --allow-insecure-entitlement network.host --allow-insecure-entitlement security.insecure

      - name: Build nginx image (single-arch for speed)
        run: |
          set -e
          TOK='${{ secrets.GHCR_TOKEN }}'
          USR='${{ secrets.GHCR_USERNAME }}'

          if [ -z "$TOK" ] || [ -z "$USR" ]; then
            echo "Error: GHCR_TOKEN and GHCR_USERNAME secrets must be set"
            exit 1
          fi

          success=0
          for i in 1 2 3; do
            echo "Attempt $i: Logging in to GHCR..."
            echo "$TOK" | docker login ${{ env.REGISTRY }} -u "$USR" --password-stdin

            # Build for linux/amd64 only for faster builds
            if docker buildx build \
              --platform linux/amd64 \
              --provenance=false \
              --sbom=false \
              --cache-from type=local,src=/tmp/.buildx-cache \
              --cache-from type=registry,ref=${{ env.NGINX_IMAGE }}:buildcache \
              --cache-to type=local,dest=/tmp/.buildx-cache-new,mode=max \
              --cache-to type=registry,ref=${{ env.NGINX_IMAGE }}:buildcache,mode=max \
              -t ${{ env.NGINX_IMAGE }}:latest \
              -f nginx/Dockerfile \
              --push .; then
              echo "Nginx image buildx push succeeded"
              success=1
              # Move cache to avoid growing cache indefinitely
              rm -rf /tmp/.buildx-cache
              mv /tmp/.buildx-cache-new /tmp/.buildx-cache
              break
            fi

            echo "Attempt $i failed; retrying in $((i*10))s..."
            sleep $((i*10))
          done

          if [ "$success" != 1 ]; then
            echo "Nginx image buildx push failed after 3 attempts"
            exit 1
          fi

      - name: Capture image digest
        id: capture-digest
        run: |
          set -e
          echo "Fetching nginx image digest..."
          DIGEST=$(docker buildx imagetools inspect ${{ env.NGINX_IMAGE }}:latest --format '{{json .}}' | jq -r '.manifest.digest')
          echo "Nginx digest: $DIGEST"

          if [ -z "$DIGEST" ] || [ "$DIGEST" = "null" ]; then
            echo "ERROR: Failed to get nginx digest"
            exit 1
          fi

          echo "digest=$DIGEST" >> $GITHUB_OUTPUT

  sync-to-s3:
    name: Sync assets to S3 & invalidate CloudFront
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    permissions:
      contents: read
      actions: read
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download build artifact from CI run
        uses: dawidd6/action-download-artifact@v6
        with:
          run_id: ${{ github.event.workflow_run.id }}
          name: nextjs-build
          path: .
          github_token: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract and verify build artifact
        run: |
          if [ ! -f "next-build.tar.gz" ]; then
            echo "Error: next-build.tar.gz not found!"
            exit 1
          fi
          tar -xzf next-build.tar.gz

          if [ ! -d ".next" ] || [ ! -d ".next/static" ] || [ ! -f ".next/BUILD_ID" ]; then
            echo "Error: Missing expected .next output after extraction"
            ls -la .next 2>/dev/null || echo ".next directory not found"
            exit 1
          fi
          echo "✓ Build artifact extracted and verified"

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "22.12.0"

      - name: Install minimal dependencies for sync script
        run: npm install --no-save @aws-sdk/client-s3 @aws-sdk/client-cloudfront @aws-sdk/lib-storage dotenv mime tsx

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Sync static assets to S3
        env:
          S3_BUCKET: ${{ secrets.S3_BUCKET }}
          CDN_DOMAIN: ${{ secrets.CDN_DOMAIN }}
          SKIP_BUILD: "true"
          CLOUDFRONT_DISTRIBUTION_ID: ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }}
          SKIP_INVALIDATION: "true"
        run: |
          echo "Syncing Next.js static assets to S3..."
          npx tsx scripts/sync-cdn.ts

      - name: Invalidate CloudFront distribution
        env:
          CLOUDFRONT_DISTRIBUTION_ID: ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }}
        run: |
          if [ -z "$CLOUDFRONT_DISTRIBUTION_ID" ]; then
            echo "CLOUDFRONT_DISTRIBUTION_ID not set, skipping invalidation"
            exit 0
          fi

          echo "Creating CloudFront invalidation..."
          aws cloudfront create-invalidation \
            --distribution-id "$CLOUDFRONT_DISTRIBUTION_ID" \
            --paths "/*" \
            --query 'Invalidation.Id' \
            --output text

          echo "✓ CloudFront invalidation created successfully"

  deploy:
    name: Deploy to EC2 via SSH with temporary IP allow
    runs-on: ubuntu-latest
    needs: [build-images, build-nginx, sync-to-s3]
    permissions:
      contents: read
      id-token: write
    env:
      WEBSITE_IMAGE: ghcr.io/${{ github.repository_owner }}/boudreaux/website
      NGINX_IMAGE: ghcr.io/${{ github.repository_owner }}/boudreaux/nginx
      # Align secret names: ensure AWS_SECURITY_GROUP_ID exists in repo secrets
      AWS_SECURITY_GROUP_ID: ${{ secrets.AWS_SECURITY_GROUP_ID }}
      # Toggle: set to 'true' to fail deploy if self-signed cert remains after issuance attempts
      REQUIRE_TRUSTED_CERT: ${{ vars.REQUIRE_TRUSTED_CERT || 'false' }}
      WEBSITE_DIGEST: ${{ needs.build-images.outputs.digest }}
      NGINX_DIGEST: ${{ needs.build-nginx.outputs.digest }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Validate image digests
        run: |
          echo "Will deploy with digests:"
          echo "  Website: $WEBSITE_DIGEST"
          echo "  Nginx: $NGINX_DIGEST"

          if [ -z "$WEBSITE_DIGEST" ] || [ "$WEBSITE_DIGEST" = "null" ]; then
            echo "ERROR: Missing website image digest"
            exit 1
          fi
          if [ -z "$NGINX_DIGEST" ] || [ "$NGINX_DIGEST" = "null" ]; then
            echo "ERROR: Missing nginx image digest"
            exit 1
          fi

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Ensure Security Groups allow HTTP/HTTPS on all attached SGs
        run: |
          set -e

          # Why: EC2 instances can have multiple Security Groups attached.
          # If ANY Security Group lacks HTTP/HTTPS rules, traffic is blocked (Security Groups are stateful AND gates).
          # We auto-discover all SGs attached to the instance and ensure 80/443 are open on each.

          # Discover instance ID by Elastic IP or tag (adjust filter as needed)
          INSTANCE_ID=$(aws ec2 describe-instances \
            --filters "Name=instance-state-name,Values=running" "Name=tag:Name,Values=*" \
            --query 'Reservations[0].Instances[0].InstanceId' \
            --output text 2>/dev/null || echo "")

          if [ -z "$INSTANCE_ID" ] || [ "$INSTANCE_ID" = "None" ]; then
            echo "WARNING: Could not auto-discover instance. Falling back to AWS_SECURITY_GROUP_ID if set."
            if [ -n "${{ env.AWS_SECURITY_GROUP_ID }}" ]; then
              SG_IDS="${{ env.AWS_SECURITY_GROUP_ID }}"
            else
              echo "ERROR: No instance found and AWS_SECURITY_GROUP_ID not set. Cannot ensure Security Group rules."
              exit 1
            fi
          else
            echo "Found instance: $INSTANCE_ID"
            # Get all Security Groups attached to this instance
            SG_IDS=$(aws ec2 describe-instances \
              --instance-ids "$INSTANCE_ID" \
              --query 'Reservations[0].Instances[0].SecurityGroups[*].GroupId' \
              --output text)
          fi

          echo "Security Groups to configure: $SG_IDS"

          # For each Security Group, ensure HTTP/HTTPS are open
          # Why 0.0.0.0/0? This is a public website; visitors come from any IP globally.
          # Port 80: Needed for Let's Encrypt ACME HTTP-01 challenges and HTTP→HTTPS redirect
          # Port 443: HTTPS traffic for the website
          for SG_ID in $SG_IDS; do
            echo "Ensuring ports 80/443 open on $SG_ID..."

            # Add IPv4 rules (idempotent; ignore "already exists" errors)
            aws ec2 authorize-security-group-ingress \
              --group-id "$SG_ID" \
              --ip-permissions IpProtocol=tcp,FromPort=80,ToPort=80,IpRanges='[{CidrIp=0.0.0.0/0,Description="HTTP for web traffic and Let'\''s Encrypt"}]' \
              2>&1 | grep -v "already exists" || true

            aws ec2 authorize-security-group-ingress \
              --group-id "$SG_ID" \
              --ip-permissions IpProtocol=tcp,FromPort=443,ToPort=443,IpRanges='[{CidrIp=0.0.0.0/0,Description="HTTPS for web traffic"}]' \
              2>&1 | grep -v "already exists" || true

            # Optional: Add IPv6 rules (ignore errors if VPC doesn't support IPv6)
            aws ec2 authorize-security-group-ingress \
              --group-id "$SG_ID" \
              --ip-permissions IpProtocol=tcp,FromPort=80,ToPort=80,Ipv6Ranges='[{CidrIpv6=::/0,Description="HTTP IPv6"}]' \
              2>&1 | grep -v -E "already exists|InvalidParameterValue" || true

            aws ec2 authorize-security-group-ingress \
              --group-id "$SG_ID" \
              --ip-permissions IpProtocol=tcp,FromPort=443,ToPort=443,Ipv6Ranges='[{CidrIpv6=::/0,Description="HTTPS IPv6"}]' \
              2>&1 | grep -v -E "already exists|InvalidParameterValue" || true
          done

          echo "Security Group configuration complete."

      - name: Get runner public IP
        id: ip
        uses: haythem/public-ip@v1.3

      - name: Temporarily whitelist runner IP for SSH on all Security Groups
        run: |
          # Why: GitHub Actions runners use dynamic IPs. We temporarily allow SSH from the current runner IP,
          # then revoke it after deployment completes. This must be done on ALL attached Security Groups.

          # Reuse the instance discovery logic
          INSTANCE_ID=$(aws ec2 describe-instances \
            --filters "Name=instance-state-name,Values=running" "Name=tag:Name,Values=*" \
            --query 'Reservations[0].Instances[0].InstanceId' \
            --output text 2>/dev/null || echo "")

          if [ -z "$INSTANCE_ID" ] || [ "$INSTANCE_ID" = "None" ]; then
            # Fallback to env var if discovery fails
            SG_IDS="${{ env.AWS_SECURITY_GROUP_ID }}"
          else
            SG_IDS=$(aws ec2 describe-instances \
              --instance-ids "$INSTANCE_ID" \
              --query 'Reservations[0].Instances[0].SecurityGroups[*].GroupId' \
              --output text)
          fi

          echo "Adding temporary SSH access from ${{ steps.ip.outputs.ipv4 }} to: $SG_IDS"

          for SG_ID in $SG_IDS; do
            aws ec2 authorize-security-group-ingress \
              --group-id "$SG_ID" \
              --protocol tcp \
              --port 22 \
              --cidr "${{ steps.ip.outputs.ipv4 }}/32" \
              2>&1 | grep -v "already exists" || true
          done

      - name: Create .env for remote
        run: |
          cat > .env.deploy << 'EOF'
          NEXT_APP_WEBSITE_IMAGE=${{ env.WEBSITE_IMAGE }}
          NEXT_APP_NGINX_IMAGE=${{ env.NGINX_IMAGE }}
          DATABASE_URL=${{ secrets.DATABASE_URL }}
          AUTH_SECRET=${{ secrets.AUTH_SECRET }}
          AUTH_URL=${{ secrets.AUTH_URL }}
          EMAIL_SERVER_HOST=${{ secrets.EMAIL_SERVER_HOST }}
          EMAIL_SERVER_PORT=${{ secrets.EMAIL_SERVER_PORT }}
          EMAIL_SERVER_USER=${{ secrets.EMAIL_SERVER_USER }}
          EMAIL_SERVER_PASSWORD=${{ secrets.EMAIL_SERVER_PASSWORD }}
          EMAIL_FROM=${{ secrets.EMAIL_FROM }}
          NEXT_PUBLIC_CLOUDFLARE_SITE_KEY=${{ secrets.NEXT_PUBLIC_CLOUDFLARE_SITE_KEY }}
          CLOUDFLARE_SECRET=${{ secrets.CLOUDFLARE_SECRET }}
          AWS_REGION=${{ secrets.AWS_REGION }}
          AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}
          S3_BUCKET=${{ secrets.S3_BUCKET }}
          CDN_DOMAIN=${{ secrets.CDN_DOMAIN }}
          EOF

      - name: Upload compose + env
        uses: appleboy/scp-action@v0.1.7
        with:
          # Align secret names: EC2_HOST, EC2_USERNAME, SSH_PRIVATE_KEY
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USERNAME }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          source: docker-compose.prod.yml,.env.deploy
          target: ~/boudreaux

      - name: Deploy via SSH
        uses: appleboy/ssh-action@v1.2.0
        env:
          LETSENCRYPT_EMAIL: ${{ secrets.LETSENCRYPT_EMAIL }}
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USERNAME }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          timeout: 60s
          command_timeout: 30m
          envs: WEBSITE_DIGEST,NGINX_DIGEST,REQUIRE_TRUSTED_CERT,LETSENCRYPT_EMAIL
          script: |
            set -euo pipefail

            # Ensure project directory exists with correct structure
            mkdir -p ~/boudreaux
            mkdir -p ~/boudreaux/.deploy

            # Check available disk space (fail if less than 2GB free)
            echo "Checking available disk space..."
            AVAILABLE_GB=$(df -BG / | awk 'NR==2 {print $4}' | sed 's/G//')
            echo "Available disk space: ${AVAILABLE_GB}GB"

            if [ "$AVAILABLE_GB" -lt 2 ]; then
              echo "⚠️  WARNING: Low disk space (${AVAILABLE_GB}GB available)"
              echo "Running Docker cleanup to free space..."
              docker system prune -af --volumes || true

              AVAILABLE_GB=$(df -BG / | awk 'NR==2 {print $4}' | sed 's/G//')
              echo "After cleanup: ${AVAILABLE_GB}GB available"

              if [ "$AVAILABLE_GB" -lt 1 ]; then
                echo "❌ ERROR: Insufficient disk space (${AVAILABLE_GB}GB). Need at least 1GB free."
                exit 1
              fi
            else
              echo "✓ Sufficient disk space available"
            fi

            # Create certbot-webroot with sudo if permission denied
            if [ ! -d ~/boudreaux/certbot-webroot ]; then
              sudo mkdir -p ~/boudreaux/certbot-webroot/.well-known/acme-challenge
              sudo chown -R $(whoami):$(id -gn) ~/boudreaux/certbot-webroot
              sudo chmod -R 755 ~/boudreaux/certbot-webroot
            fi

            # Ensure SSH authorized_keys has correct permissions
            mkdir -p ~/.ssh
            chmod 700 ~/.ssh
            if [ -f ~/.ssh/authorized_keys ]; then
              chmod 600 ~/.ssh/authorized_keys
            fi

            cd ~/boudreaux
            TARGET_DIR="$(pwd)"
            LOCAL_USER="$(whoami)"
            LOCAL_GROUP="$(id -gn)"

            # Ensure Docker is installed and running (Ubuntu)
            if ! command -v docker >/dev/null 2>&1; then
              sudo apt-get update
              sudo apt-get remove -y docker.io docker-doc docker-compose podman-docker containerd runc 2>/dev/null || true
              sudo apt-get install -y ca-certificates curl gnupg lsb-release
              if [ ! -f /etc/apt/keyrings/docker.gpg ]; then
                sudo install -m 0755 -d /etc/apt/keyrings
                curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
                sudo chmod a+r /etc/apt/keyrings/docker.gpg
                echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
                sudo apt-get update
              fi
              sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
              sudo systemctl enable docker
              sudo systemctl start docker
            fi

            # Ensure user is in docker group (required for non-root Docker access)
            if ! groups | grep -q docker; then
              echo "Adding $USER to docker group..."
              sudo usermod -aG docker $USER
              echo "User added to docker group. Note: This session will use 'sudo docker' for remaining commands."
              echo "Subsequent deployments will not need sudo after the user logs out and back in."
            fi

            # Check if we can access Docker without sudo (define DOCKER_CMD early)
            if docker ps >/dev/null 2>&1; then
              DOCKER_CMD="docker"
            else
              echo "Using sudo for Docker commands (group membership not yet active in this session)"
              DOCKER_CMD="sudo docker"
            fi

            # Log certificate enforcement setting and current mode
            echo "Certificate enforcement: REQUIRE_TRUSTED_CERT=${REQUIRE_TRUSTED_CERT}"
            if [ -f "$HOME/boudreaux/.selfsigned" ]; then
              echo "Current TLS mode: self-signed (marker present)"
            else
              echo "Current TLS mode: trusted (no self-signed marker)"
            fi

            # Install certbot if not present (one-time setup)
            if ! command -v certbot >/dev/null 2>&1; then
              echo "Installing certbot..."
              sudo apt-get update -qq
              sudo apt-get install -y certbot
            fi

            # Setup Let's Encrypt certificates
            DOMAIN="fakefourrecords.com"
            CERT_PATH="/etc/letsencrypt/live/$DOMAIN"

            # Configure email args for certbot (supports no-email fallback)
            if [ -n "${LETSENCRYPT_EMAIL:-}" ]; then
              CERTBOT_EMAIL_ARGS=(--email "$LETSENCRYPT_EMAIL")
            else
              echo "WARNING: LETSENCRYPT_EMAIL is not set; proceeding without registration email."
              CERTBOT_EMAIL_ARGS=(--register-unsafely-without-email)
            fi

            # Check if certificate needs acquisition or renewal
            NEEDS_CERT=false
            if ! sudo test -f "$CERT_PATH/fullchain.pem"; then
              echo "No certificate found at $CERT_PATH — need initial issuance."
              NEEDS_CERT=true
            else
              # Check if existing cert is expired or expiring within 30 days
              echo "Checking certificate expiration..."
              CERT_EXPIRY=$(sudo openssl x509 -enddate -noout -in "$CERT_PATH/fullchain.pem" 2>/dev/null | cut -d= -f2 || true)
              if [ -n "$CERT_EXPIRY" ]; then
                echo "Certificate expires: $CERT_EXPIRY"
                if ! sudo openssl x509 -checkend 2592000 -noout -in "$CERT_PATH/fullchain.pem" 2>/dev/null; then
                  echo "⚠️  Certificate is expired or expiring within 30 days — forcing renewal."
                  NEEDS_CERT=true
                else
                  echo "✓ Certificate is valid for more than 30 days."
                fi
              else
                echo "WARNING: Could not read certificate expiration — forcing renewal."
                NEEDS_CERT=true
              fi
            fi

            if [ "$NEEDS_CERT" = true ]; then
              echo "Obtaining/renewing Let's Encrypt certificate for $DOMAIN..."

              # Try renewal first WITHOUT stopping containers (works if cert uses webroot authenticator)
              # The renewal config at /etc/letsencrypt/renewal/$DOMAIN.conf determines the method
              if sudo certbot renew --cert-name "$DOMAIN" --force-renewal --non-interactive; then
                echo "✓ Certificate renewed successfully via certbot renew (with containers running)."
              else
                echo "certbot renew failed with containers running — trying with containers stopped..."

                # Stop containers that might be using port 80 (needed for standalone authenticator)
                $DOCKER_CMD stop nginx website 2>/dev/null || true

                # Retry renewal with containers stopped (works if cert uses standalone authenticator)
                if sudo certbot renew --cert-name "$DOMAIN" --force-renewal --non-interactive; then
                  echo "✓ Certificate renewed successfully via certbot renew (with containers stopped)."
                else
                  echo "certbot renew failed — no existing cert found, trying initial issuance..."

                  # Request certificate using standalone mode (first-time issuance)
                  sudo certbot certonly --standalone --non-interactive --agree-tos \
                    "${CERTBOT_EMAIL_ARGS[@]}" \
                    -d "$DOMAIN" -d "www.$DOMAIN" || {
                    echo "WARNING: Standalone certificate acquisition failed."
                  }
                fi
              fi
            fi

            # Always copy the latest cert from letsencrypt to deployment directory
            # This ensures the deployed cert matches what certbot has, even if
            # renewal happened outside the deploy (e.g., via cron) but the local
            # certificate.pem was never updated
            # Note: sudo required because /etc/letsencrypt/live/ is root-only (drwx------)
            if sudo test -f "$CERT_PATH/fullchain.pem"; then
              echo "Installing Let's Encrypt certificate to deployment directory..."
              sudo install -o "$LOCAL_USER" -g "$LOCAL_GROUP" -m 644 "$CERT_PATH/fullchain.pem" "$TARGET_DIR/certificate.pem"
              sudo install -o "$LOCAL_USER" -g "$LOCAL_GROUP" -m 600 "$CERT_PATH/privkey.pem" "$TARGET_DIR/private_key.pem"
              sudo chmod 644 "$TARGET_DIR/certificate.pem"
              sudo chmod 600 "$TARGET_DIR/private_key.pem"

              # Verify the deployed cert is not expired before proceeding
              if sudo openssl x509 -checkend 0 -noout -in "$TARGET_DIR/certificate.pem" 2>/dev/null; then
                DEPLOY_EXPIRY=$(sudo openssl x509 -enddate -noout -in "$TARGET_DIR/certificate.pem" | cut -d= -f2)
                echo "✓ Deployed certificate is valid (expires: $DEPLOY_EXPIRY)"
              else
                OPENSSL_STATUS=$?
                if [ "$OPENSSL_STATUS" -eq 1 ]; then
                  echo "❌ ERROR: Deployed certificate is expired even after renewal attempt."
                  echo "Removing stale cert files so self-signed fallback can take over."
                  rm -f "$TARGET_DIR/certificate.pem" "$TARGET_DIR/private_key.pem"
                else
                  echo "❌ ERROR: Failed to verify deployed certificate with openssl (exit code: $OPENSSL_STATUS)."
                  echo "Leaving existing certificate files in place. Check certificate PEM, permissions, and openssl output on the server."
                fi
              fi

              # Setup automatic renewal cron (idempotent)
              # This ensures certificate auto-renewal even if cert was issued outside of deployment
              echo "Ensuring automatic certificate renewal cron job is configured..."
              if ! sudo crontab -l 2>/dev/null | grep -Fq "certbot renew"; then
                CRON_CMD="0 3 * * * certbot renew --deploy-hook \"install -o $LOCAL_USER -g $LOCAL_GROUP -m 644 $CERT_PATH/fullchain.pem $TARGET_DIR/certificate.pem && install -o $LOCAL_USER -g $LOCAL_GROUP -m 600 $CERT_PATH/privkey.pem $TARGET_DIR/private_key.pem && chmod 600 $TARGET_DIR/private_key.pem && chmod 644 $TARGET_DIR/certificate.pem && (docker restart nginx || true)\" >> /var/log/certbot-renew.log 2>&1"
                (sudo crontab -l 2>/dev/null; printf '%s\n' "$CRON_CMD") | sudo crontab -
                echo "✓ Cron job added: Certificate will auto-renew daily at 3 AM"
              else
                echo "✓ Cron job already configured"
              fi

              # Remove self-signed marker if present
              if [ -f "$HOME/boudreaux/.selfsigned" ]; then
                rm -f "$HOME/boudreaux/.selfsigned"
                echo "Removed self-signed marker; Let's Encrypt certs are active."
              fi
            fi

            # Fallback: create self-signed cert if no valid cert exists
            if [ ! -f "$HOME/boudreaux/certificate.pem" ] || [ ! -f "$HOME/boudreaux/private_key.pem" ]; then
              echo "Generating temporary self-signed certificate to satisfy compose secrets..."
              # Ensure openssl is available
              if ! command -v openssl >/dev/null 2>&1; then
                sudo apt-get update -qq
                sudo apt-get install -y openssl
              fi
              # Create self-signed cert valid for 30 days
              openssl req -x509 -nodes -newkey rsa:2048 -days 30 \
                -subj "/CN=${DOMAIN}" \
                -keyout "$HOME/boudreaux/private_key.pem" \
                -out "$HOME/boudreaux/certificate.pem"
              sudo chmod 600 "$HOME/boudreaux/private_key.pem" || true
              sudo chmod 644 "$HOME/boudreaux/certificate.pem" || true
              # Mark that we're using a temporary self-signed cert
              touch "$HOME/boudreaux/.selfsigned"
              echo "Self-signed certificate created; will attempt Let's Encrypt issuance after containers start."
            fi

            # Move env into place and secure permissions
            mv -f .env.deploy .env
            chmod 600 .env  # Owner read/write only

            # Login to GHCR using aligned credentials
            echo '${{ secrets.GHCR_TOKEN }}' | $DOCKER_CMD login ghcr.io -u '${{ secrets.GHCR_USERNAME }}' --password-stdin

            WEBSITE_IMAGE='${{ env.WEBSITE_IMAGE }}'
            NGINX_IMAGE='${{ env.NGINX_IMAGE }}'

            # Capture previously deployed digests (for rollback if needed)
            PREV_WEBSITE_DIGEST=$($DOCKER_CMD inspect --format '{{index .RepoDigests 0}}' "$WEBSITE_IMAGE" 2>/dev/null || true)
            PREV_NGINX_DIGEST=$($DOCKER_CMD inspect --format '{{index .RepoDigests 0}}' "$NGINX_IMAGE" 2>/dev/null || true)

            # CRITICAL: Remove old :latest tagged images to prevent Docker from using stale cache
            echo "Removing old :latest images to force fresh pull..."
            $DOCKER_CMD rmi "$WEBSITE_IMAGE:latest" 2>/dev/null || true
            $DOCKER_CMD rmi "$NGINX_IMAGE:latest" 2>/dev/null || true

            # If digests are provided, pin to those; otherwise, use latest and capture digests
            if [ -n "${WEBSITE_DIGEST:-}" ] && [ -n "${NGINX_DIGEST:-}" ]; then
              echo "Using provided digests for deployment"
              echo "  Website: $WEBSITE_DIGEST"
              echo "  Nginx: $NGINX_DIGEST"

              # Pull by fully qualified digest (image@sha256:...)
              $DOCKER_CMD pull "$WEBSITE_IMAGE@$WEBSITE_DIGEST" || {
                echo "❌ Failed to pull website image with digest"
                exit 1
              }
              $DOCKER_CMD pull "$NGINX_IMAGE@$NGINX_DIGEST" || {
                echo "❌ Failed to pull nginx image with digest"
                exit 1
              }

              # Tag with :latest for compose to use
              $DOCKER_CMD tag "$WEBSITE_IMAGE@$WEBSITE_DIGEST" "$WEBSITE_IMAGE:latest"
              $DOCKER_CMD tag "$NGINX_IMAGE@$NGINX_DIGEST" "$NGINX_IMAGE:latest"
              NEW_WEBSITE_DIGEST="$WEBSITE_IMAGE@$WEBSITE_DIGEST"
              NEW_NGINX_DIGEST="$NGINX_IMAGE@$NGINX_DIGEST"
            else
              echo "No digests provided; using latest tags"
              $DOCKER_CMD pull "$WEBSITE_IMAGE:latest" || true
              $DOCKER_CMD pull "$NGINX_IMAGE:latest" || true
              NEW_WEBSITE_DIGEST=$($DOCKER_CMD inspect --format '{{index .RepoDigests 0}}' "$WEBSITE_IMAGE:latest" 2>/dev/null || true)
              NEW_NGINX_DIGEST=$($DOCKER_CMD inspect --format '{{index .RepoDigests 0}}' "$NGINX_IMAGE:latest" 2>/dev/null || true)
            fi

            # Restart stack (force remove any conflicting containers)
            echo "Stopping existing containers..."
            $DOCKER_CMD compose -f docker-compose.prod.yml down --remove-orphans || true

            # Remove any containers with conflicting names
            echo "Removing old containers..."
            $DOCKER_CMD rm -f website nginx 2>/dev/null || true

            # Verify images are fresh (should match digests we just pulled)
            echo "Verifying fresh images..."
            CURRENT_WEBSITE_ID=$($DOCKER_CMD images "$WEBSITE_IMAGE:latest" --format "{{.ID}}")
            CURRENT_NGINX_ID=$($DOCKER_CMD images "$NGINX_IMAGE:latest" --format "{{.ID}}")
            echo "  Website image ID: $CURRENT_WEBSITE_ID"
            echo "  Nginx image ID: $CURRENT_NGINX_ID"

            echo "Starting containers with fresh images..."
            $DOCKER_CMD compose -f docker-compose.prod.yml up -d --force-recreate

            # Verify containers are running
            echo "Verifying containers started successfully..."
            sleep 5
            RUNNING_CONTAINERS=$($DOCKER_CMD ps --format '{{.Names}}' | grep -E 'website|nginx' | wc -l)
            if [ "$RUNNING_CONTAINERS" -lt 2 ]; then
              echo "ERROR: Expected 2 containers (website, nginx) but found $RUNNING_CONTAINERS"
              $DOCKER_CMD ps -a
              $DOCKER_CMD compose -f docker-compose.prod.yml logs --tail=50
              exit 1
            fi
            echo "✓ Both containers are running"

            # Verify containers are healthy before proceeding
            echo "Verifying container health..."
            CONTAINER_COUNT=$($DOCKER_CMD ps --filter "name=website" --filter "name=nginx" --format '{{.Names}}' | wc -l)
            if [ "$CONTAINER_COUNT" -lt 2 ]; then
              echo "❌ ERROR: Expected 2 containers but found $CONTAINER_COUNT"
              $DOCKER_CMD ps -a
              exit 1
            fi
            echo "✓ Both containers running"

            # Give containers time to fully start serving content
            sleep 5

            # Basic health check (allow insecure only if using a temporary self-signed cert)
            echo "Running health check..."
            CURL_OPTS="-fsS --max-time 10"
            if [ -f "$HOME/boudreaux/.selfsigned" ]; then
              echo "Self-signed cert in use; allowing insecure TLS for health check"
              CURL_OPTS="-k $CURL_OPTS"
            fi
            if ! curl $CURL_OPTS https://fakefourrecords.com/api/health; then
              echo 'Health check failed - attempting rollback'

              # Roll back to previous digests if we have them
              if [ -n "$PREV_WEBSITE_DIGEST" ]; then
                # Ensure previous digest is present and retag as :latest
                $DOCKER_CMD pull "$PREV_WEBSITE_DIGEST" || true
                $DOCKER_CMD tag "$PREV_WEBSITE_DIGEST" "$WEBSITE_IMAGE:latest" || true
              fi
              if [ -n "$PREV_NGINX_DIGEST" ]; then
                $DOCKER_CMD pull "$PREV_NGINX_DIGEST" || true
                $DOCKER_CMD tag "$PREV_NGINX_DIGEST" "$NGINX_IMAGE:latest" || true
              fi

              $DOCKER_CMD compose -f docker-compose.prod.yml up -d --force-recreate
              sleep 5
              if ! curl -fsS --max-time 10 https://fakefourrecords.com/api/health; then
                echo 'Rollback health check failed - manual intervention required'
                exit 1
              else
                echo 'Rollback successful'
              fi
            fi

            # Attempt Let's Encrypt webroot issuance if using self-signed cert
            if [ -f "$HOME/boudreaux/.selfsigned" ]; then
              echo "Self-signed certificate detected; attempting Let's Encrypt issuance via webroot with retries..."

              # Pre-flight checks before issuance
              echo "=== Pre-flight checks ==="

              # Check DNS resolution
              RESOLVED_IP=$(dig +short "$DOMAIN" | head -n1 || true)
              if [ -z "$RESOLVED_IP" ]; then
                echo "WARNING: DNS resolution failed for $DOMAIN"
              else
                echo "DNS: $DOMAIN resolves to $RESOLVED_IP"
              fi

              # Create a test challenge file and verify it is served over HTTP
              TEST_TOKEN="deploy-$(date +%s)"
              echo "$TEST_TOKEN" > "$HOME/boudreaux/certbot-webroot/.well-known/acme-challenge/_test"
              if curl -s --max-time 5 "http://$DOMAIN/.well-known/acme-challenge/_test" | grep -q "$TEST_TOKEN"; then
                echo "Port 80: Accessible (HTTP responded)"
              else
                echo "WARNING: Port 80 may be blocked or nginx not serving challenges"
                echo "Ensure Security Group allows inbound TCP 80 from 0.0.0.0/0"
              fi

              # Check if webroot directory exists and is writable
              if [ -d "$HOME/boudreaux/certbot-webroot/.well-known/acme-challenge" ]; then
                echo "Webroot: Challenge directory exists"
                if [ -w "$HOME/boudreaux/certbot-webroot/.well-known/acme-challenge" ]; then
                  echo "Webroot: Directory is writable"
                else
                  echo "WARNING: Webroot challenge directory is not writable"
                fi
              else
                echo "ERROR: Webroot challenge directory should have been created by deploy setup"
              fi

              echo "==========================="

              attempts=0
              max_attempts=3
              backoff_base=30
              while [ $attempts -lt $max_attempts ]; do
                echo "Issuance attempt $((attempts+1)) of $max_attempts"
                sudo certbot certonly --webroot -w "$HOME/boudreaux/certbot-webroot" \
                  --non-interactive --agree-tos \
                  "${CERTBOT_EMAIL_ARGS[@]}" \
                  -d "$DOMAIN" -d "www.$DOMAIN" && break || {
                    echo "Issuance attempt $((attempts+1)) failed"
                  }
                attempts=$((attempts+1))
                if [ $attempts -lt $max_attempts ]; then
                  sleep_duration=$((backoff_base * attempts))
                  echo "Sleeping $sleep_duration seconds before retry..."
                  sleep $sleep_duration
                fi
              done

              if sudo test -f "$CERT_PATH/fullchain.pem"; then
                echo "Webroot issuance succeeded; activating Let's Encrypt certificate."
                sudo install -o "$LOCAL_USER" -g "$LOCAL_GROUP" -m 644 "$CERT_PATH/fullchain.pem" "$HOME/boudreaux/certificate.pem"
                sudo install -o "$LOCAL_USER" -g "$LOCAL_GROUP" -m 600 "$CERT_PATH/privkey.pem" "$HOME/boudreaux/private_key.pem"
                sudo chmod 644 "$HOME/boudreaux/certificate.pem"
                sudo chmod 600 "$HOME/boudreaux/private_key.pem"
                rm -f "$HOME/boudreaux/.selfsigned" || true

                # Setup automatic certificate renewal cron job (runs daily at 3 AM)
                # This is idempotent - will only add the cron job if it doesn't exist
                echo "Setting up automatic certificate renewal cron job..."
                if ! sudo crontab -l 2>/dev/null | grep -Fq "certbot renew"; then
                  CRON_CMD="0 3 * * * certbot renew --deploy-hook \"install -o $LOCAL_USER -g $LOCAL_GROUP -m 644 $CERT_PATH/fullchain.pem $HOME/boudreaux/certificate.pem && install -o $LOCAL_USER -g $LOCAL_GROUP -m 600 $CERT_PATH/privkey.pem $HOME/boudreaux/private_key.pem && chmod 600 $HOME/boudreaux/private_key.pem && chmod 644 $HOME/boudreaux/certificate.pem && (docker restart nginx || true)\" >> /var/log/certbot-renew.log 2>&1"
                  (sudo crontab -l 2>/dev/null; printf '%s\n' "$CRON_CMD") | sudo crontab -
                  echo "✓ Cron job added: Certificate will auto-renew daily at 3 AM"
                else
                  echo "✓ Cron job already exists"
                fi

                # Restart nginx to pick up new secrets
                $DOCKER_CMD restart nginx || true
              else
                echo "Let's Encrypt certificate still not present after $max_attempts attempts; retaining self-signed cert."
              fi
            fi

            # Secondary certificate chain verification (does not block deploy)
            echo "Verifying presented TLS certificate chain..."
            if command -v openssl >/dev/null 2>&1; then
              CERT_INFO=$(echo | openssl s_client -connect fakefourrecords.com:443 -servername fakefourrecords.com -showcerts 2>/dev/null | openssl x509 -noout -issuer -subject || true)
              if [ -n "$CERT_INFO" ]; then
                echo "--- Certificate Info ---"
                echo "$CERT_INFO"
                SELF_SIGNED=0
                if echo "$CERT_INFO" | grep -qi "issuer=.*fakefourrecords.com"; then
                  echo "NOTE: Self-signed certificate still in use (issuer matches domain)."
                  SELF_SIGNED=1
                fi
                if [ "$SELF_SIGNED" -eq 1 ] && [ "$REQUIRE_TRUSTED_CERT" = "true" ]; then
                  echo "REQUIRE_TRUSTED_CERT=true and self-signed certificate detected; failing deploy."
                  exit 1
                fi
              else
                echo "WARNING: Unable to retrieve certificate info via openssl."
              fi
            else
              echo "openssl not available; skipping certificate chain verification."
            fi

            # Persist current digests on host for audit/rollback reference
            cat > .deploy/digests.json <<JSON
            {
              "website": {
                "prev": "${PREV_WEBSITE_DIGEST}",
                "current": "${NEW_WEBSITE_DIGEST}"
              },
              "nginx": {
                "prev": "${PREV_NGINX_DIGEST}",
                "current": "${NEW_NGINX_DIGEST}"
              }
            }
            JSON

            $DOCKER_CMD system prune -f || true

      - name: Revoke runner IP from all Security Groups
        if: always()
        run: |
          # Cleanup: Remove the temporary SSH rule we added at the start of deployment.
          # Must revoke from ALL Security Groups to avoid leaving stale rules.

          INSTANCE_ID=$(aws ec2 describe-instances \
            --filters "Name=instance-state-name,Values=running" "Name=tag:Name,Values=*" \
            --query 'Reservations[0].Instances[0].InstanceId' \
            --output text 2>/dev/null || echo "")

          if [ -z "$INSTANCE_ID" ] || [ "$INSTANCE_ID" = "None" ]; then
            SG_IDS="${{ env.AWS_SECURITY_GROUP_ID }}"
          else
            SG_IDS=$(aws ec2 describe-instances \
              --instance-ids "$INSTANCE_ID" \
              --query 'Reservations[0].Instances[0].SecurityGroups[*].GroupId' \
              --output text)
          fi

          echo "Revoking SSH access from ${{ steps.ip.outputs.ipv4 }} on: $SG_IDS"

          for SG_ID in $SG_IDS; do
            aws ec2 revoke-security-group-ingress \
              --group-id "$SG_ID" \
              --protocol tcp \
              --port 22 \
              --cidr "${{ steps.ip.outputs.ipv4 }}/32" \
              2>&1 | grep -v "does not exist" || true
          done

  version-bump:
    name: Bump version & release
    runs-on: ubuntu-latest
    needs: [deploy]
    permissions:
      contents: write
      pull-requests: read
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Find merged PR and determine bump type
        id: bump-type
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          # Get the HEAD commit SHA from the CI workflow run that triggered deploy
          COMMIT_SHA="${{ github.event.workflow_run.head_sha }}"
          echo "Looking for PR that merged commit: $COMMIT_SHA"

          # Find the PR associated with this commit
          PR_JSON=$(gh api "/repos/${{ github.repository }}/commits/${COMMIT_SHA}/pulls" \
            --jq '.[0] | {number, title, labels: [.labels[].name]}' 2>/dev/null || echo "")

          if [ -z "$PR_JSON" ] || [ "$PR_JSON" = "null" ]; then
            echo "No PR found for commit $COMMIT_SHA — skipping version bump."
            echo "skip=true" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          PR_NUMBER=$(echo "$PR_JSON" | jq -r '.number')
          PR_TITLE=$(echo "$PR_JSON" | jq -r '.title')
          LABELS=$(echo "$PR_JSON" | jq -r '.labels[]' 2>/dev/null || echo "")

          echo "PR #$PR_NUMBER: $PR_TITLE"
          echo "Labels: $LABELS"
          echo "pr_number=$PR_NUMBER" >> "$GITHUB_OUTPUT"
          echo "pr_title=$PR_TITLE" >> "$GITHUB_OUTPUT"

          if echo "$LABELS" | grep -q "version:major"; then
            echo "bump=major" >> "$GITHUB_OUTPUT"
          elif echo "$LABELS" | grep -q "version:minor"; then
            echo "bump=minor" >> "$GITHUB_OUTPUT"
          elif echo "$LABELS" | grep -q "version:patch"; then
            echo "bump=patch" >> "$GITHUB_OUTPUT"
          else
            echo "No version label found — skipping version bump."
            echo "skip=true" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          echo "skip=false" >> "$GITHUB_OUTPUT"

      - name: Setup Node.js
        if: steps.bump-type.outputs.skip != 'true'
        uses: actions/setup-node@v4
        with:
          node-version: "22.12.0"

      - name: Bump version
        if: steps.bump-type.outputs.skip != 'true'
        id: version
        run: |
          OLD_VERSION=$(jq -r '.version' package.json)
          npm version ${{ steps.bump-type.outputs.bump }} --no-git-tag-version
          NEW_VERSION=$(jq -r '.version' package.json)
          echo "old=$OLD_VERSION" >> "$GITHUB_OUTPUT"
          echo "new=$NEW_VERSION" >> "$GITHUB_OUTPUT"
          echo "tag=v$NEW_VERSION" >> "$GITHUB_OUTPUT"
          echo "Bumped: $OLD_VERSION → $NEW_VERSION"

      - name: Generate changelog entry
        if: steps.bump-type.outputs.skip != 'true'
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          VERSION="${{ steps.version.outputs.new }}"
          DATE=$(date +%Y-%m-%d)
          PR_TITLE="${{ steps.bump-type.outputs.pr_title }}"
          PR_NUMBER="${{ steps.bump-type.outputs.pr_number }}"
          BUMP_TYPE="${{ steps.bump-type.outputs.bump }}"

          # Get all merged PR titles since the last tag
          LAST_TAG=$(git describe --tags --abbrev=0 2>/dev/null || echo "")
          if [ -n "$LAST_TAG" ]; then
            COMMITS_RANGE="${LAST_TAG}..HEAD"
          else
            # No tags exist, get all commits from the beginning
            COMMITS_RANGE="HEAD"
          fi

          # Collect unique PR entries from merge commits
          MERGED_PRS=""
          SEEN_PRS=""
          while IFS= read -r sha; do
            [ -z "$sha" ] && continue
            PR_INFO=$(gh api "/repos/${{ github.repository }}/commits/${sha}/pulls" \
              --jq '.[0] | "\(.number)|\(.title)"' 2>/dev/null || true)
            if [ -n "$PR_INFO" ]; then
              PR_NUM=$(echo "$PR_INFO" | cut -d'|' -f1)
              PR_TTL=$(echo "$PR_INFO" | cut -d'|' -f2-)
              if ! echo "$SEEN_PRS" | grep -q "^${PR_NUM}$"; then
                SEEN_PRS="${SEEN_PRS}${PR_NUM}\n"
                MERGED_PRS="${MERGED_PRS}- ${PR_TTL} (#${PR_NUM})\n"
              fi
            fi
          done < <(git log ${COMMITS_RANGE} --format='%H' 2>/dev/null)

          # Always include the triggering PR if not already in the list
          if ! echo "$SEEN_PRS" | grep -q "^${PR_NUMBER}$"; then
            MERGED_PRS="${MERGED_PRS}- ${PR_TITLE} (#${PR_NUMBER})\n"
          fi

          # Final fallback: if still no PR entries, use just the triggering PR
          if [ -z "$MERGED_PRS" ]; then
            MERGED_PRS="- ${PR_TITLE} (#${PR_NUMBER})"
          fi

          # Determine section header based on bump type
          case "$BUMP_TYPE" in
            major) SECTION="### Changed" ;;
            minor) SECTION="### Added" ;;
            patch) SECTION="### Fixed" ;;
          esac

          # Build the new changelog entry
          ENTRY="## [${VERSION}] - ${DATE}\n\n${SECTION}\n\n$(echo -e "$MERGED_PRS")"

          # Prepend to CHANGELOG.md after the header block (first 7 lines)
          if [ -f CHANGELOG.md ]; then
            head -n 7 CHANGELOG.md > CHANGELOG.tmp
            echo "" >> CHANGELOG.tmp
            echo -e "$ENTRY" >> CHANGELOG.tmp
            echo "" >> CHANGELOG.tmp
            tail -n +8 CHANGELOG.md >> CHANGELOG.tmp
            mv CHANGELOG.tmp CHANGELOG.md
          else
            printf '%s\n\n%s\n\n%b\n' \
              "# Changelog" \
              "All notable changes to this project will be documented in this file." \
              "$ENTRY" > CHANGELOG.md
          fi

      - name: Commit, tag, and push
        if: steps.bump-type.outputs.skip != 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add package.json package-lock.json CHANGELOG.md
          git commit -m "chore(release): v${{ steps.version.outputs.new }} [skip ci]"
          git tag "${{ steps.version.outputs.tag }}"
          git push origin main --follow-tags

      - name: Create GitHub Release
        if: steps.bump-type.outputs.skip != 'true'
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          VERSION="${{ steps.version.outputs.new }}"

          # Extract the new version's section from CHANGELOG.md for release notes
          NOTES=$(awk -v ver="$VERSION" '
            /^## \[/ {
              if (found) exit
              if (index($0, "[" ver "]")) found=1
              next
            }
            found { print }
          ' CHANGELOG.md)

          if [ -z "$NOTES" ]; then
            NOTES="Release v$VERSION"
          fi

          echo "$NOTES" > release-notes.txt

          gh release create "${{ steps.version.outputs.tag }}" \
            --title "${{ steps.version.outputs.tag }}" \
            --notes-file release-notes.txt \
            --target main
